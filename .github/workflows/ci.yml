name: CI

# This workflow runs comprehensive testing including:
# - Unit tests across multiple OS and Python versions
# - Integration tests with and without ChromaDB
# - E2E tests with real ChromaDB (v1.0.16+)
# - Coverage reporting with real ChromaDB
# - Performance benchmarks
# - Security scanning
# - Build and packaging validation

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.12"

jobs:
  # Code quality checks
  lint:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          uv sync --dev
          uv pip install pre-commit

      - name: Cache pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-
        continue-on-error: true

      - name: Run pre-commit
        run: uv run pre-commit run --all-files
        continue-on-error: false

      - name: Run ruff check
        run: uv run ruff check src/ tests/

      - name: Run ruff format check
        run: uv run ruff format --check src/ tests/

      - name: Run mypy
        run: uv run mypy src/

  # Test matrix across multiple Python versions
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.12", "3.13"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Install dependencies
        run: uv sync --dev --extra chromadb

      - name: Run unit tests
        run: uv run pytest tests/unit/ -v --tb=short --strict-markers

      - name: Run integration tests (without ChromaDB)
        run: uv run pytest tests/integration/ -v --tb=short --strict-markers -m "not chromadb"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
          path: |
            .pytest_cache/
            *.log

  # Coverage testing with ChromaDB service - simplified approach
  coverage:
    runs-on: ubuntu-latest
    services:
      chromadb:
        image: chromadb/chroma:1.0.16 # Minimum supported version
        ports:
          - 8000:8000
        env:
          ANONYMIZED_TELEMETRY: "false"
          ALLOW_RESET: "true"
          IS_PERSISTENT: "true"
        # Remove built-in health checks - handle externally
        options: >-
          --name chromadb-service

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --dev --extra chromadb

      - name: Wait for ChromaDB to be ready
        run: |
          echo "ðŸ” Waiting for ChromaDB service to be ready..."
          timeout=180
          elapsed=0
          interval=5

          echo "ðŸ“‹ Container status:"
          docker ps --filter name=chromadb-service --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

          while [ $elapsed -lt $timeout ]; do
            echo "â³ Waiting... ($elapsed/${timeout}s elapsed)"
            
            # Check if we can connect to any compatible API endpoint
            if curl -f --max-time 10 --connect-timeout 5 -s http://localhost:8000/api/v2/heartbeat >/dev/null 2>&1; then
              echo "âœ… ChromaDB v2 API is ready"
              break
            elif curl -f --max-time 10 --connect-timeout 5 -s http://localhost:8000/api/v1/heartbeat >/dev/null 2>&1; then
              echo "âœ… ChromaDB v1 API is ready"
              break
            elif curl -f --max-time 10 --connect-timeout 5 -s http://localhost:8000/heartbeat >/dev/null 2>&1; then
              echo "âœ… ChromaDB root API is ready"
              break
            fi
            
            # Show debug info every 30 seconds
            if [ $((elapsed % 30)) -eq 0 ] && [ $elapsed -gt 0 ]; then
              echo "ðŸ” Debug info at ${elapsed}s:"
              echo "Container status:"
              docker ps --filter name=chromadb-service --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" || true
              echo "Container logs (last 10 lines):"
              docker logs --tail 10 chromadb-service 2>/dev/null || true
              echo "Port connectivity:"
              nc -z localhost 8000 && echo "Port 8000 is reachable" || echo "Port 8000 is not reachable"
            fi
            
            sleep $interval
            elapsed=$((elapsed + interval))
          done

          if [ $elapsed -ge $timeout ]; then
            echo "âŒ ChromaDB failed to start within ${timeout} seconds"
            echo "ðŸ“‹ Final debug info:"
            echo "Container status:"
            docker ps -a --filter name=chromadb-service --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" || true
            echo "Container logs:"
            docker logs chromadb-service || true
            echo "Network connectivity test:"
            curl -v --max-time 10 http://localhost:8000/api/v2/heartbeat || true
            exit 1
          fi

          echo "âœ… ChromaDB is ready and accessible"

      - name: Verify ChromaDB API endpoints
        run: |
          echo "ðŸ” Verifying ChromaDB API endpoints..."

          # Test the available endpoints
          base_url="http://localhost:8000"

          echo "Testing v2 API (preferred):"
          if curl -f -s --max-time 10 "${base_url}/api/v2/heartbeat"; then
            echo "âœ… v2 API working"
            api_version="v2"
          elif curl -f -s --max-time 10 "${base_url}/api/v1/heartbeat"; then
            echo "âœ… v1 API working"
            api_version="v1"
          elif curl -f -s --max-time 10 "${base_url}/heartbeat"; then
            echo "âœ… Root API working"
            api_version="root"
          else
            echo "âŒ No working API found"
            exit 1
          fi

          echo "ðŸŽ‰ Using ChromaDB API version: $api_version"

      - name: Run tests with coverage
        env:
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
          COVERAGE_FILE: .coverage
          SHARD_MD_USE_MOCK_CHROMADB: "false" # Ensure real ChromaDB is used
        run: |
          # Run ALL tests including e2e with real ChromaDB
          uv run pytest \
            --cov=shard_markdown \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            tests/
          TEST_EXIT_CODE=$?

          # Check coverage threshold (informational only, don't fail the build)
          echo ""
          echo "ðŸ“Š Checking coverage threshold (informational):"
          uv run coverage report --fail-under=80 || {
            echo "âš ï¸ Coverage is below 80% threshold - this is informational only and won't fail the build"
            echo "â„¹ï¸ To improve coverage, add more tests for uncovered code paths"
          }

          # Exit with the test exit code (fail only if tests failed, not coverage)
          exit $TEST_EXIT_CODE

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            coverage.xml
            htmlcov/

  # Build and package testing
  build:
    runs-on: ubuntu-latest
    needs: [lint, test, e2e-tests] # Also wait for e2e tests to pass
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install build dependencies
        run: uv sync --dev --extra chromadb

      - name: Build package
        run: uv build

      - name: Test package installation
        run: |
          # Test wheel installation
          uv pip install dist/*.whl
          uv run shard-md --help

          # Test source distribution
          uv pip uninstall shard-markdown
          uv pip install dist/*.tar.gz
          uv run shard-md --help

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/

  # Performance benchmarks
  benchmark:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --dev

      - name: Run benchmarks
        run: uv run pytest tests/performance/ --benchmark-only --benchmark-json=benchmark.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark.json

  # Security scanning
  security:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --dev

      - name: Run safety check
        run: uv run safety check --json

      - name: Run bandit security scan
        run: |
          uv pip install bandit[toml]
          uv run bandit -r src/ -f json -o bandit-report.json

      - name: Upload security scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json

  # E2E and integration tests with real ChromaDB
  e2e-tests:
    runs-on: ubuntu-latest
    needs: [lint] # Run after linting passes

    services:
      chromadb:
        image: chromadb/chroma:1.0.16 # Minimum supported version
        ports:
          - 8000:8000
        env:
          ANONYMIZED_TELEMETRY: "false"
          ALLOW_RESET: "true"
          IS_PERSISTENT: "true"
        # Remove built-in health checks - handle externally
        options: >-
          --name chromadb-e2e-service

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --dev --extra chromadb

      - name: Wait for ChromaDB to be ready
        run: |
          echo "ðŸ” Waiting for ChromaDB service to be ready..."
          timeout=180
          elapsed=0
          interval=5

          echo "ðŸ“‹ Container status:"
          docker ps --filter name=chromadb-e2e-service --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

          while [ $elapsed -lt $timeout ]; do
            echo "â³ Waiting... ($elapsed/${timeout}s elapsed)"
            
            # Check if we can connect to any compatible API endpoint
            if curl -f --max-time 10 --connect-timeout 5 -s http://localhost:8000/api/v2/heartbeat >/dev/null 2>&1; then
              echo "âœ… ChromaDB v2 API is ready"
              break
            elif curl -f --max-time 10 --connect-timeout 5 -s http://localhost:8000/api/v1/heartbeat >/dev/null 2>&1; then
              echo "âœ… ChromaDB v1 API is ready"
              break
            elif curl -f --max-time 10 --connect-timeout 5 -s http://localhost:8000/heartbeat >/dev/null 2>&1; then
              echo "âœ… ChromaDB root API is ready"
              break
            fi
            
            # Show debug info every 30 seconds
            if [ $((elapsed % 30)) -eq 0 ] && [ $elapsed -gt 0 ]; then
              echo "ðŸ” Debug info at ${elapsed}s:"
              echo "Container status:"
              docker ps --filter name=chromadb-e2e-service --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" || true
              echo "Container logs (last 10 lines):"
              docker logs --tail 10 chromadb-e2e-service 2>/dev/null || true
              echo "Port connectivity:"
              nc -z localhost 8000 && echo "Port 8000 is reachable" || echo "Port 8000 is not reachable"
            fi
            
            sleep $interval
            elapsed=$((elapsed + interval))
          done

          if [ $elapsed -ge $timeout ]; then
            echo "âŒ ChromaDB failed to start within ${timeout} seconds"
            echo "ðŸ“‹ Final debug info:"
            echo "Container status:"
            docker ps -a --filter name=chromadb-e2e-service --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" || true
            echo "Container logs:"
            docker logs chromadb-e2e-service || true
            echo "Network connectivity test:"
            curl -v --max-time 10 http://localhost:8000/api/v2/heartbeat || true
            exit 1
          fi

          echo "âœ… ChromaDB is ready and accessible"

      - name: Run E2E tests with real ChromaDB
        env:
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
          SHARD_MD_USE_MOCK_CHROMADB: "false"
        run: |
          echo "ðŸ§ª Running E2E tests with ChromaDB 1.0.16"
          uv run pytest tests/e2e/ -v --tb=short --strict-markers
          echo "âœ… E2E tests passed"

      - name: Run integration tests with ChromaDB marker
        env:
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
        run: |
          echo "ðŸ§ª Running integration tests that require ChromaDB"
          uv run pytest tests/integration/ -v --tb=short --strict-markers -m "chromadb" || echo "No tests marked with chromadb in integration"

      - name: Test CLI with real ChromaDB
        env:
          CHROMA_HOST: localhost
          CHROMA_PORT: 8000
        run: |
          echo "ðŸ§ª Testing CLI commands with real ChromaDB"

          # Create a test collection
          uv run shard-md collections create ci-test-collection || {
            echo "âš ï¸ Failed to create collection"
            exit 1
          }

          # Create test document
          echo "# CI Test Document" > ci-test.md
          echo "Testing ChromaDB integration in CI pipeline." >> ci-test.md

          # Process document
          uv run shard-md process --collection ci-test-collection ci-test.md

          # Query document
          uv run shard-md query search "integration" --collection ci-test-collection

          # Clean up
          uv run shard-md collections delete ci-test-collection || echo "Collection cleanup failed"

          echo "âœ… CLI tests passed"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: e2e-test-results
          path: |
            .pytest_cache/
            *.log
